Inception Attack - Technical Explanation

Overview
The Inception Attack is a rule-based prompt mutation attack that uses the EasyJailbreak library to automatically transform input prompts. It applies predefined mutation rules to generate adversarial variations of prompts that can be used to test model robustness.

How the Attack Works

1. Loading Prompts
The attack reads prompts from a CSV file. It first checks for recognized column names (Original_prompt, prompt, query, goal, harmful_prompt, text). If none exist, it uses the first column as the prompt source.

2. Applying Inception Mutation
The Inception attack applies a series of rule-based transformations using the EasyJailbreak library's built-in mutation strategies. These transformations include:
- Text modification techniques
- Structural reorganization
- Semantic-preserving rewrites
- Prompt reformulation

3. Generating Mutations
For each input prompt, the attack generates one mutated version by applying the Inception mutation rule from the EasyJailbreak library. The original prompt and mutated version are recorded.

4. Output Generation
The results are saved to a CSV file with two columns:
- original_prompt: The input prompt before mutation
- mutated_prompt: The transformed prompt generated by the Inception rule

5. Logging Results
All mutations are logged with their original and mutated variants for analysis and evaluation.

Key Features
- Deterministic rule-based mutations
- Fast execution compared to model-based attacks
- No GPU required
- Consistent reproducibility
- Compatible with various prompt formats

Usage
The attack can be run by providing a CSV file path as a command-line argument:
python Inception.py <csv_file_path>

The mutation rules are applied automatically to each prompt, and results are saved in the specified output directory.
